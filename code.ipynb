{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_wTEMmPxa6jD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        ")\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 1: Load and inspect dataset\n",
        "# ----------------------------------\n",
        "df = pd.read_csv(\"diabetes.csv\")\n",
        "\n",
        "# Initial inspection\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nData Types:\\n\", df.dtypes)\n",
        "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
        "print(\"\\nStatistical Summary:\\n\", df.describe())\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 2: Data Cleaning\n",
        "# ----------------------------------\n",
        "\n",
        "# Columns where 0 is biologically invalid\n",
        "invalid_zero_cols = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
        "\n",
        "# Replace 0s with NaN for better imputation\n",
        "for col in invalid_zero_cols:\n",
        "    df[col] = df[col].replace(0, np.nan)\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values after replacement:\\n\", df.isnull().sum())\n",
        "\n",
        "# Visualize missing values\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df.isnull(), cbar=False, cmap=\"viridis\")\n",
        "plt.title(\"Missing Values Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "# Impute using median\n",
        "df.fillna(df.median(), inplace=True)\n",
        "\n",
        "# Additional cleaning: removing outliers using z-score\n",
        "from scipy.stats import zscore\n",
        "\n",
        "z_scores = np.abs(zscore(df))\n",
        "df_clean = df[(z_scores < 3).all(axis=1)]\n",
        "\n",
        "print(\"\\nOriginal dataset size:\", df.shape[0])\n",
        "print(\"Cleaned dataset size:\", df_clean.shape[0])\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 3: Visualizations\n",
        "# ----------------------------------\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.histplot(df_clean[\"Age\"], kde=True)\n",
        "plt.title(\"Age Distribution\")\n",
        "\n",
        "plt.figure(figsize=(20, 6))\n",
        "pd.crosstab(df_clean.Age, df_clean.Outcome).plot(kind=\"bar\", figsize=(20, 6), color=[\"yellow\", \"blue\"])\n",
        "plt.title(\"Disease Frequency for Ages\")\n",
        "plt.xlabel(\"Age\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(df_clean.corr(), annot=True, cmap=\"coolwarm\")\n",
        "plt.title(\"Feature Correlation\")\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 4: Train-Test Split & Scaling\n",
        "# ----------------------------------\n",
        "\n",
        "X = df_clean.drop(\"Outcome\", axis=1)\n",
        "y = df_clean[\"Outcome\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.2, random_state=42)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 5: Model Setup\n",
        "# ----------------------------------\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"SVM\": SVC(probability=True),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "}\n",
        "\n",
        "accuracies = {}\n",
        "best_model = None\n",
        "best_accuracy = 0\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 6: Training and Evaluation\n",
        "# ----------------------------------\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    accuracies[name] = acc * 100\n",
        "\n",
        "    print(f\"\\n{name} Accuracy: {acc * 100:.2f}%\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
        "    disp.plot(cmap=\"Blues\")\n",
        "    plt.title(f\"{name} - Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    if acc > best_accuracy:\n",
        "        best_accuracy = acc\n",
        "        best_model = model\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 7: Model Comparison\n",
        "# ----------------------------------\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=list(accuracies.keys()), y=list(accuracies.values()), palette=\"viridis\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Model Accuracy Comparison\")\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 8: Hyperparameter Tuning (for best model type)\n",
        "# ----------------------------------\n",
        "\n",
        "if isinstance(best_model, RandomForestClassifier):\n",
        "    param_grid = {\n",
        "        \"n_estimators\": [50, 100, 150],\n",
        "        \"max_depth\": [3, 5, 10],\n",
        "        \"criterion\": [\"gini\", \"entropy\"],\n",
        "    }\n",
        "elif isinstance(best_model, KNeighborsClassifier):\n",
        "    param_grid = {\n",
        "        \"n_neighbors\": [3, 5, 7],\n",
        "        \"weights\": [\"uniform\", \"distance\"],\n",
        "    }\n",
        "elif isinstance(best_model, SVC):\n",
        "    param_grid = {\n",
        "        \"C\": [0.1, 1, 10],\n",
        "        \"kernel\": [\"linear\", \"rbf\"],\n",
        "    }\n",
        "else:\n",
        "    param_grid = {}\n",
        "\n",
        "if param_grid:\n",
        "    grid = GridSearchCV(best_model, param_grid, cv=3, n_jobs=-1)\n",
        "    grid.fit(X_train, y_train)\n",
        "    print(\"\\nBest Parameters Found:\\n\", grid.best_params_)\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 9: Summary\n",
        "# ----------------------------------\n",
        "\n",
        "print(\"\\nFinal Accuracy Scores:\")\n",
        "for model_name, score in accuracies.items():\n",
        "    print(f\"{model_name}: {score:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Project_code1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
